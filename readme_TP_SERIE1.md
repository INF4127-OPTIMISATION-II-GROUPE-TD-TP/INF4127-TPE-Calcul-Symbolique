<div align="center">

# ğŸ“ TPE: Analyse convexe avec SymPy

## INF4127 - Optimisation II

</div>

---

## ğŸ“„ Description

Ce dÃ©pÃ´t contient le **TP INF4127 â€” Optimisation II** (Fiche de TPE nÂ°1) : Ã©tude symbolique et numÃ©rique des fonctions de perte (MSE, BCE, CCE / softmax, Huber), leurs gradients et Hessiennes, vÃ©rification des propriÃ©tÃ©s de convexitÃ©, visualisations (2D/3D/heatmaps) et applications sur petits jeux de donnÃ©es (rÃ©gression et classification).

Le travail utilise **Python**, **SymPy** pour le calcul symbolique, **NumPy / SciPy / scikit-learn / Matplotlib** pour la partie numÃ©rique et graphique.

---

## ğŸ“Œ Objectifs du TP

- Calculer les gradients et Hessiennes des fonctions de perte demandÃ©es.  
- Ã‰tudier rigoureusement la convexitÃ© (analyse via Hessienne).  
- Appliquer les fonctions sur des jeux de donnÃ©es (n<100, 2 attributs).  
- Visualiser les surfaces de perte, lignes de niveau et tangentes Ã  une ellipse (application gÃ©omÃ©trique).  
- Fournir des vÃ©rifications numÃ©riques.

---

## ğŸ‘¥ Ã‰quipe du projet

| Nom & PrÃ©nom | Matricule | RÃ´le |
|---|:---:|:---:|
| ESSUTHI MBANGUE ANGE ARMEL | 24F2456 | Membre |
| TAGNE TALLA IDRISS CHANEL | 19M2351 | Membre |
| DJATCHE NKAMGANG SYLVANO | 22W2163 | Membre |
| GOUJOU GUIMATSA ZIDANE | 21T2899 | Membre |

---

## ğŸ“ Contenu principal

- `TP_INF4127_OptimisationII.ipynb` â€” Notebook Jupyter enrichi : dÃ©monstrations symboliques, vÃ©rifications numÃ©riques, visualisations et exercices guidÃ©s.  
- `README_TP_INF4127.md` â€” Ce fichier (prÃ©sentation, instructions et auteurs).  


---

## ğŸ› ï¸ PrÃ©requis

Assurez-vous d'avoir Python 3.8+ et installez les dÃ©pendances :

```bash
pip install numpy scipy sympy matplotlib scikit-learn seaborn jupyterlab
```

---

## â–¶ï¸ Lancer le notebook

1. Ouvrir un terminal dans le dossier du projet.  
2. DÃ©marrer JupyterLab / Jupyter Notebook :

```bash
jupyter lab
# ou
jupyter notebook
```

3. Ouvrir `TP_INF4127_OptimisationII.ipynb`.  
4. ExÃ©cuter les cellules (de haut en bas). Le notebook est prÃªt Ã  l'emploi et inclut des exemples numÃ©riques et graphiques.

> Remarque : pour la partie symbolique (SymPy), le notebook utilise `sp.init_printing()` pour un affichage lisible. Si vous exÃ©cutez sur un serveur distant, activez l'affichage graphique (X11) ou tÃ©lÃ©chargez les figures gÃ©nÃ©rÃ©es.

---

## ğŸ”¬ Jeux de donnÃ©es utilisÃ©s

- **RÃ©gression** : jeu synthÃ©tique linÃ©aire (n â‰ˆ 80â€“100, 2 features) gÃ©nÃ©rÃ© dans le notebook.  
- **Classification** : jeu synthÃ©tique (ou jeu Iris rÃ©duit Ã  2 classes/2 features).  

Ces jeux de donnÃ©es sont petits pour faciliter l'exÃ©cution sur une machine personnelle et pour les besoins pÃ©dagogiques du TP.

---

## ğŸ§¾ RÃ©sultats et livrables

- Notebook prÃªt Ã  exÃ©cution : `TP_INF4127_OptimisationII_Ameliore.ipynb`.  
- Graphiques : courbes 1D, surfaces 3D, heatmaps et visualisation de tangente Ã  l'ellipse.  
- SynthÃ¨se et tableau comparatif des pertes en fin de notebook.

---



## ğŸ“š RÃ©fÃ©rences

- Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*.  
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*.  
- Documentation SymPy et scikit-learn.

---

## ğŸ“ Licence

Le contenu de ce TP est fourni pour un usage pÃ©dagogique. Vous pouvez le rÃ©utiliser en citant les auteurs.

---


